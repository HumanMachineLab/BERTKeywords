{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55255922-37f6-4194-942d-fc078de55b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run if working locally\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc4f25d6-44bb-4936-89cc-e42b38a51650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "import pickle\n",
    "import os, sys\n",
    "import config\n",
    "\n",
    "config.root_path = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.insert(0, config.root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d965590f-99f3-41e0-928a-012c5881c2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.similarities import Embedding, Similarities\n",
    "from src.keywords import Keyword, Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e4882eb-5c08-475a-9d71-bd39f51cf8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.keywords import Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6e764d6-8701-4bde-b248-ff0e4d5b29db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ad4690d22574fdd8bf93c3ce3b8a006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d7d6bb6d253425b8edc7184d6225946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/miniforge3/envs/phd/lib/python3.8/site-packages/transformers/utils/generic.py:319: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "# Set gpu_layers to the number of layers to offload to GPU. \n",
    "# Set to 0 if no GPU acceleration is available on your system.\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"TheBloke/Mistral-7B-Instruct-v0.1-GGUF\",\n",
    "    model_file=\"mistral-7b-instruct-v0.1.Q4_K_M.gguf\",\n",
    "    model_type=\"mistral\",\n",
    "    gpu_layers=2,\n",
    "    hf=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6597baae-a9d8-4994-b0d8-369ce4b1117b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a79f5a5ddd43aaada2f4b7cf8926f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.47k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "614964bd9d5c4f5eabdfff7c3a517594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9241a97f57b4627a8899fcaff5c354b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65dafcec252045f8a46c633b492d6473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n",
    "\n",
    "# Pipeline\n",
    "generator = pipeline(\n",
    "    model=model, tokenizer=tokenizer,\n",
    "    task='text-generation',\n",
    "    max_new_tokens=50,\n",
    "    repetition_penalty=1.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3a8f1b0-d5e2-425d-8b50-f9537536f0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is 1+1?\n",
      "A: 2\n"
     ]
    }
   ],
   "source": [
    "response = generator(\"What is 1+1?\")\n",
    "print(response[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6be9058b-8954-4911-aab8-36cf2fd98783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I have the following document:\n",
      "* The website mentions that it only takes a couple of days to deliver but I still have not received mine\n",
      "\n",
      "Extract 5 keywords from that document.\n",
      "\n",
      "**Answer:**\n",
      "1. Website\n",
      "2. Deliver\n",
      "3. Couple\n",
      "4. Days\n",
      "5. Mention\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "I have the following document:\n",
    "* The website mentions that it only takes a couple of days to deliver but I still have not received mine\n",
    "\n",
    "Extract 5 keywords from that document.\n",
    "\"\"\"\n",
    "response = generator(prompt)\n",
    "print(response[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "620ea504-6fe5-44f0-8e81-364f513679b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = \"\"\"\n",
    "<s>[INST]\n",
    "I have the following document:\n",
    "- The website mentions that it only takes a couple of days to deliver but I still have not received mine.\n",
    "\n",
    "Please give me the keywords that are present in this document and separate them with commas.\n",
    "Make sure you to only return the keywords and say nothing else. For example, don't say:\n",
    "\"Here are the keywords present in the document\"\n",
    "[/INST] meat, beef, eat, eating, emissions, steak, food, health, processed, chicken</s>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "888bf1c8-8718-4bfb-acc5-cf5dcff9d27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_prompt = \"\"\"\n",
    "[INST]\n",
    "I have the following document:\n",
    "- [DOCUMENT]\n",
    "\n",
    "Please give me the keywords that are present in this document and separate them with commas.\n",
    "Make sure you to only return the keywords and say nothing else. For example, don't say:\n",
    "\"Here are the keywords present in the document\"\n",
    "[/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eef8aefb-7f32-4523-a7b5-7044061794d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = example_prompt + keyword_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dcd1d7c-8722-4d8d-afbe-360e92dae8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keybert.llm import TextGeneration\n",
    "from keybert import KeyLLM\n",
    "\n",
    "# Load it in KeyLLM\n",
    "llm = TextGeneration(generator, prompt=prompt)\n",
    "kw_model = KeyLLM(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b82facf5-0bbc-4c60-8958-13c74d85b77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "\"The website mentions that it only takes a couple of days to deliver but I still have not received mine.\",\n",
    "\"I received my package!\",\n",
    "\"Whereas the most powerful LLMs have generally been accessible only through limited APIs (if at all), Meta released LLaMA's model weights to the research community under a noncommercial license.\"\n",
    "]\n",
    "\n",
    "keywords = kw_model.extract_keywords(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1d5efa4-408b-4594-99fe-045d9489478c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name bert-base-uncased. Creating a new one with MEAN pooling.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities = Similarities('bert-base-uncased')\n",
    "embedding = Embedding(similarities.model, similarities.tokenizer)\n",
    "\n",
    "keywords_helper = Keywords(similarities.model, similarities.tokenizer)\n",
    "keywords_helper.get_word_embedding('this is a sentence and a sentence', 'sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31173d04-7c01-41b7-9da0-208cb703d627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_helper.get_word_embedding(documents[0], keywords[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65bbb3fc-19bc-4c34-a895-8ef26e54039f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m kw_model \u001b[38;5;241m=\u001b[39m KeyLLM(llm)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Extract keywords\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m keywords, _ \u001b[38;5;241m=\u001b[39m kw_model\u001b[38;5;241m.\u001b[39mextract_keywords(\n\u001b[1;32m     13\u001b[0m     documents, \n\u001b[1;32m     14\u001b[0m     embeddings\u001b[38;5;241m=\u001b[39membeddings, \n\u001b[1;32m     15\u001b[0m     threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.5\u001b[39m\n\u001b[1;32m     16\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "from keybert import KeyLLM\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Extract embeddings\n",
    "model = SentenceTransformer('BAAI/bge-small-en-v1.5')\n",
    "embeddings = model.encode(documents, convert_to_tensor=True)\n",
    "\n",
    "# Load it in KeyLLM\n",
    "kw_model = KeyLLM(llm)\n",
    "\n",
    "# Extract keywords\n",
    "keywords, _ = kw_model.extract_keywords(\n",
    "    documents, \n",
    "    embeddings=embeddings, \n",
    "    threshold=.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a49d4e-bc99-44c9-8c6b-3d041452ed5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba3b58e3-6a1c-4f9a-b5a3-7ed7848b145a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['website',\n",
       "  'mention',\n",
       "  'days',\n",
       "  'deliver',\n",
       "  'couple',\n",
       "  'receive',\n",
       "  'mine',\n",
       "  'still',\n",
       "  'not',\n",
       "  'yet'],\n",
       " ['website',\n",
       "  'mention',\n",
       "  'days',\n",
       "  'deliver',\n",
       "  'couple',\n",
       "  'receive',\n",
       "  'mine',\n",
       "  'still',\n",
       "  'not',\n",
       "  'yet'],\n",
       " ['LLM',\n",
       "  'API',\n",
       "  'accessibility',\n",
       "  'release',\n",
       "  'license',\n",
       "  'research',\n",
       "  'community',\n",
       "  'model',\n",
       "  'weights',\n",
       "  'Meta',\n",
       "  'power',\n",
       "  'availability',\n",
       "  'commercial',\n",
       "  'noncommercial',\n",
       "  'language',\n",
       "  'models',\n",
       "  'development',\n",
       "  'collaboration',\n",
       "  'openness',\n",
       "  'sharing',\n",
       "  'innovation',\n",
       "  'technology',\n",
       "  'artificial']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f498e58b-face-439e-a6b2-27b86bb7ea08",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m kw_model \u001b[38;5;241m=\u001b[39m KeyBERT(llm\u001b[38;5;241m=\u001b[39mllm, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBAAI/bge-small-en-v1.5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Extract keywords\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m keywords \u001b[38;5;241m=\u001b[39m \u001b[43mkw_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_keywords\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/phd/lib/python3.8/site-packages/keybert/_model.py:259\u001b[0m, in \u001b[0;36mKeyBERT.extract_keywords\u001b[0;34m(self, docs, candidates, keyphrase_ngram_range, stop_words, top_n, min_df, use_maxsum, use_mmr, diversity, nr_candidates, vectorizer, highlight, seed_keywords, doc_embeddings, word_embeddings, threshold)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m--> 259\u001b[0m     doc_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc_embeddings\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(all_keywords[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    261\u001b[0m         candidate_keywords \u001b[38;5;241m=\u001b[39m [[keyword[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m keyword \u001b[38;5;129;01min\u001b[39;00m all_keywords]]\n",
      "File \u001b[0;32m~/miniforge3/envs/phd/lib/python3.8/site-packages/torch/cuda/__init__.py:293\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    289\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    291\u001b[0m     )\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    296\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    297\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "from keybert import KeyLLM, KeyBERT\n",
    "\n",
    "# Load it in KeyLLM\n",
    "kw_model = KeyBERT(llm=llm, model='BAAI/bge-small-en-v1.5')\n",
    "\n",
    "# Extract keywords\n",
    "keywords = kw_model.extract_keywords(documents, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c779354b-8639-46ec-bf35-037803b778db",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
